{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33af0fd-a184-4c92-9eaf-7cff77566bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1993cbbb-23c5-4386-99c4-2f21c23322a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd4df68-63c2-487b-bcee-0b5e53d63b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1516c390-4608-4c7a-8b10-ac5db0345b6b",
   "metadata": {},
   "source": [
    "# Conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d03546b-d0ea-4fb5-8733-be32922f1a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a443b94-0046-4478-98cf-8f206775e0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cfg: \n",
    "\n",
    "    # to store HF pre-trained models weights and configs\n",
    "    HF_CACHE_ROOT = os.path.join(\"..\", \"..\", \"..\",\n",
    "                                 \"data\",\n",
    "                                 \"05_cache\", \n",
    "                                 \"HF\"\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b7ad6d-bd51-4686-ab66-23eee5dbba7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "637c562c-bdd4-49c4-b146-8bf00b2761df",
   "metadata": {},
   "source": [
    "# HF Cache management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a559588-5447-4ff6-b3d9-469375880aaa",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/datasets/en/cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe82edf-6a4e-455f-8566-c9b55fb97490",
   "metadata": {},
   "source": [
    "- HF_HUB_CACHE: to change this -> Hugging Face Hub (such as models, tokenizers, or raw dataset sources), which are located in ~/.cache/huggingface/hub\n",
    "\n",
    "**Setting Environment Variables needs to be done before importanting transformers libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "644f4af8-4ac6-4e63-bff1-015cba5cb1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_HOME: None\n"
     ]
    }
   ],
   "source": [
    "print(\"HF_HOME:\", os.environ.get(\"HF_HOME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5abcff7f-b8d1-4f2f-b784-f899a3cd2929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_HOME: ../../../data/05_cache/HF\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"HF_HOME\"] = cfg.HF_CACHE_ROOT\n",
    "print(\"HF_HOME:\", os.environ.get(\"HF_HOME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b59211b3-848d-4d43-aae7-6b93c5be6149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_HUB_CACHE: None\n",
      "HF_HUB_CACHE: ../../../data/05_cache/HF\n"
     ]
    }
   ],
   "source": [
    "print(\"HF_HUB_CACHE:\", os.environ.get(\"HF_HUB_CACHE\"))\n",
    "os.environ[\"HF_HUB_CACHE\"] = cfg.HF_CACHE_ROOT\n",
    "print(\"HF_HUB_CACHE:\", os.environ.get(\"HF_HUB_CACHE\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ac1942-43e5-4732-b9a2-a24fbd7d3eae",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5e1f5ac-d89d-4662-983a-389654246bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "#_________\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d350df9e-06f1-4f78-a07e-efd1a502abeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be99807b-f036-4e37-928a-99ffb5fdb9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3540eec7-d0d3-41ef-889e-a35a2ba0f6fb",
   "metadata": {},
   "source": [
    "# Service Token Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0210827b-75e0-4ac7-8c28-f882ab81b363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token loaded: Yes\n"
     ]
    }
   ],
   "source": [
    "# Verify token is loaded\n",
    "load_dotenv()\n",
    "\n",
    "HF_TOKEN_READ = os.getenv(\"07_FR_phone_TokenType_READ\")\n",
    "print(f\"Token loaded: {'Yes' if HF_TOKEN_READ else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f898023-6199-48c5-bb4a-d45fd542bdf0",
   "metadata": {},
   "source": [
    "# Chapter 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf695a51-6eab-4411-8282-6be3dd3626c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c40f66-09d3-4ac2-a9c6-b26b3ba71524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb241305-b38f-4377-8e86-5e0bec793f49",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710be00e-b985-41ee-be29-1067c4ed63cd",
   "metadata": {},
   "source": [
    "**Level 1 â€” Pipelines (task orchestration)**\n",
    "\n",
    "Pipelines answer:\n",
    "\n",
    "> *â€œWhat task am I solving, end-to-end?â€*\n",
    "\n",
    "They:\n",
    "\n",
    "* define **preprocessing**\n",
    "* select **default model class**\n",
    "* define **postprocessing**\n",
    "* hide tensors, losses, and heads\n",
    "\n",
    "Examples:\n",
    "\n",
    "* `text-classification`\n",
    "* `token-classification`\n",
    "* `automatic-speech-recognition`\n",
    "* `feature-extraction`\n",
    "\n",
    "ðŸ’¡ Pipelines are **task-centric**, not model-centric.\n",
    "\n",
    "---\n",
    "\n",
    "**Level 2 â€” Model classes (architecture + task intent)**\n",
    "\n",
    "This is the most important layer.\n",
    "\n",
    "A) **Backbone / encoder models (task-agnostic)**\n",
    "\n",
    "Examples:\n",
    "\n",
    "* `BertModel`\n",
    "* `RobertaModel`\n",
    "* `Wav2Vec2Model`\n",
    "* `WhisperEncoder`\n",
    "\n",
    "They output:\n",
    "\n",
    "* hidden states\n",
    "* embeddings\n",
    "* no loss\n",
    "* no task assumptions\n",
    "\n",
    "âœ… **Truly task-agnostic**\n",
    "\n",
    "Used for:\n",
    "\n",
    "* feature extraction\n",
    "* custom heads\n",
    "* research\n",
    "* multi-task setups\n",
    "\n",
    "---\n",
    "\n",
    "B) **Task head models (task-declaring)**\n",
    "\n",
    "Examples:\n",
    "\n",
    "* `BertForSequenceClassification`\n",
    "* `BertForTokenClassification`\n",
    "* `BertForQuestionAnswering`\n",
    "* `Wav2Vec2ForCTC`\n",
    "* `WhisperForConditionalGeneration`\n",
    "\n",
    "These:\n",
    "\n",
    "* wrap a backbone\n",
    "* add a task-specific head\n",
    "* define a **forward signature**\n",
    "* define **loss computation**\n",
    "\n",
    "âš ï¸ Important nuance:\n",
    "\n",
    "> They are **task-declaring**, not always task-exclusive.\n",
    "\n",
    "(Details below ðŸ‘‡)\n",
    "\n",
    "---\n",
    "\n",
    "**Level 3 â€” Checkpoints (weights)**\n",
    "\n",
    "Checkpoints store:\n",
    "\n",
    "* backbone weights\n",
    "* head weights (if present)\n",
    "* config metadata\n",
    "\n",
    "Examples:\n",
    "\n",
    "* `bert-base-uncased`\n",
    "* `facebook/wav2vec2-base-960h`\n",
    "* `bert-base-uncased-finetuned-mrpc`\n",
    "\n",
    "Checkpoints **do not enforce tasks**.\n",
    "They **fit into** model classes â€” not the other way around.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad30d5fd-3c12-4158-a06f-bba18a48808f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cebfb38-2751-49d3-9efa-7e46f3c32e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26417dc-c366-47fc-ac03-0f8c901d6e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2f47e2-8e96-4f91-8ef1-b90c78f7c899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc583dd-4acf-4cc0-b6a6-3efea8afe9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd02a16d-9d4b-477a-b3d3-bedcadab6571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(pipeline)\n",
    "# parameters description of transformers.pipeline() \n",
    "#  https://huggingface.co/docs/transformers/v5.0.0/en/main_classes/pipelines#transformers.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee68926b-dfe8-4c71-a479-83920497ae71",
   "metadata": {},
   "source": [
    "## task: Zero-shot-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0b580d-59c9-4a28-8291-f8f7372e0aaa",
   "metadata": {},
   "source": [
    "* it would return this pipeline: `ZeroShotClassificationPipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e73380-c673-4394-bcc1-2b377b95c433",
   "metadata": {},
   "source": [
    "**warnings**\n",
    "- No model was supplied,\n",
    "    - defaulted to facebook/bart-large-mnli and revision d7645e1.\n",
    "\n",
    "Using a pipeline without specifying a model name and revision in production is not recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b65b634-99ab-48f2-a6d4-385cf7ab9731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1.\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e191c713633b48c19c79653bdb62e0bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56173900154f4dc986a8ae71fcdbe6f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5561e9bf988540ceb34739acb13d5c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd41efe62f4f4fb0bf198da300c636dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5f25527c2649d887694adbab6a778e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a834473eed24de0b7fcb3fa39e1ae65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f92fc748c454503bf9197371acb9a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-trained model weigths & config here:\n",
      " --> ../../../data/05_cache/HF\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transformers library',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.8445959687232971, 0.11197645217180252, 0.04342765733599663]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(task=\"zero-shot-classification\",\n",
    "                      token=HF_TOKEN_READ,\n",
    "                     )\n",
    "print(f\"pre-trained model weigths & config here:\\n --> {cfg.HF_CACHE_ROOT}\")\n",
    "\n",
    "classifier(\n",
    "    \"This is a course about the Transformers library\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983ec3b0-0c23-455a-a348-4729124c0d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e31186f-b9d1-4cbd-a794-656d5eef0498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bcf89f-9c7a-4510-83c6-726734a94357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf150fd0-d634-4fb7-8219-989f44391c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9510e616-de0e-4e84-b5d7-132c6141e002",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
